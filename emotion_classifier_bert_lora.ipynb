{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brnn043/EmotionClassifierAI/blob/main/emotion_classifier_bert_lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI0rwg9Tk4Gi"
      },
      "source": [
        "# ü§ñ Emotion Classifier with Lightweight Fine-Tuning\n",
        "\n",
        "Classify text into one of **six core emotions** using a compact and efficient AI model.\n",
        "\n",
        "This model is built on a **pre-trained BERT** backbone and fine-tuned with **LoRA (Low-Rank Adaptation)** ‚Äî a lightweight method that updates only a small portion of the model‚Äôs parameters. This makes it **fast**, **memory-efficient**, and suitable for resource-constrained environments.\n",
        "\n",
        "\n",
        "### üß† Model Details\n",
        "\n",
        "- **Model type:** BERT (Bidirectional Encoder Representations from Transformers)  \n",
        "- **Fine-tuning method:** LoRA (Low-Rank Adaptation)  \n",
        "- **Framework:** ü§ó Hugging Face Transformers + PEFT (Parameter-Efficient Fine-Tuning)\n",
        "\n",
        "\n",
        "### üí¨ Supported Emotions\n",
        "\n",
        "- üò¢ **Sadness**\n",
        "- üòÑ **Joy**\n",
        "- üíñ **Love**\n",
        "- üò† **Anger**\n",
        "- üò± **Fear**\n",
        "- üò≤ **Surprise**\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHQUM3v_lwOs"
      },
      "source": [
        "## Setup & Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6LAkXGk2OnGB"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip --quiet\n",
        "\n",
        "!pip install numpy==1.26.4 --quiet\n",
        "\n",
        "!pip install --upgrade transformers datasets peft evaluate --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZJExAmtl380"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKUQ69XaK5T0",
        "outputId": "f11138b6-5ca0-4659-e4d4-eefc6fec7cdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': Value('string'), 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'])}\n",
            "{'train': SplitInfo(name='train', num_bytes=1743533, num_examples=16000, shard_lengths=None, dataset_name='emotion'), 'validation': SplitInfo(name='validation', num_bytes=214945, num_examples=2000, shard_lengths=None, dataset_name='emotion'), 'test': SplitInfo(name='test', num_bytes=217423, num_examples=2000, shard_lengths=None, dataset_name='emotion')}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset_builder\n",
        "\n",
        "ds_builder = load_dataset_builder(\"dair-ai/emotion\")\n",
        "\n",
        "print(ds_builder.info.features)\n",
        "print(ds_builder.info.splits)\n",
        "print(ds_builder.info.description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UAq1lNFJAFhQ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"dair-ai/emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBmDtkdHEsBe",
        "outputId": "c1b2ef77-b4d8-4c49-ef60-0d9b88108436"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i didnt feel humiliated',\n",
              " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              " 'im grabbing a minute to post i feel greedy wrong',\n",
              " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              " 'i am feeling grouchy',\n",
              " 'ive been feeling a little burdened lately wasnt sure why that was',\n",
              " 'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny',\n",
              " 'i feel as confused about life as a teenager or as jaded as a year old man',\n",
              " 'i have been with petronas for years i feel that petronas has performed well and made a huge profit',\n",
              " 'i feel romantic too']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train']['text'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SwiBfDiHHZeR"
      },
      "outputs": [],
      "source": [
        "label_map = {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\"\n",
        "}\n",
        "\n",
        "string_map = {\n",
        "    \"sadness\": 0,\n",
        "    \"joy\": 1,\n",
        "    \"love\": 2,\n",
        "    \"anger\": 3,\n",
        "    \"fear\": 4,\n",
        "    \"surprise\": 5\n",
        "}\n",
        "\n",
        "def label_to_string(label):\n",
        "    return label_map[label]\n",
        "\n",
        "def string_to_label(string):\n",
        "    return string_map[string]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnQw0VxJGaMl"
      },
      "source": [
        "## Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "4885cf8a79fe4f159aeaa4e00d11b02f",
            "8eaaa6c74e3e45748221043a824cf4cb",
            "a85e52efc88c4fbd8b41ee40d86a1be9",
            "bb3f855aea1c4aa9a5626eaff6ed53e0",
            "b503016fd9924315b403eac78960bff7",
            "dcba513c78c247d1a0ab6ad8bda6f376",
            "64430937f01948f7a1e90d27a6b69dac",
            "89011db8b52b4a15b5cc9845a27cd4a1",
            "aa913cb4a02a42a8b0381676ee1541ef",
            "8ccfad3aeb364fb08b183b590a9a7f4f",
            "fb789d167cd34835894b44463642c1f6",
            "4979cd76548a43599714d61174477995",
            "bb3218c02d2e4b32b125e550a736ca20",
            "de6726c4d63d4549b48f02e372d23303",
            "4d832a50eb134e61b997471f31fea26a",
            "fb9ea8f4cf6c4e58b3b6e7bab0b23c2d",
            "b47092f5e4ce47299d4f2c113c4134e8",
            "f363bed2e9164a70816a55f94913ad04",
            "6149ea216c2c4ece9eaa7052e61aef1a",
            "b87934eb36784842940e974de9322445",
            "00111560656e4f87b7538eb321f2cb3c",
            "652fd3deac344b0aa4b77ea16eb3c805",
            "9040628fe39841b0aaffe8fe19b616e1",
            "c1e1d1a0727943dea4981fa64f7fe513",
            "958870486fb44c7e8dcdcecf6222bb16",
            "660b90e438654bfaaf0286a2a5824a1c",
            "1db1df6bcfea49beb48ac8560e761737",
            "d5eb3cb0098849799ceadc09595ed8b7",
            "a5487f51bdb046bcaa2e49df0a1adb40",
            "f311a024c2f9432c84d8547ed734ac1e",
            "965d82e40a7f4e26be5163aca342fd17",
            "e4199befa7bd4fb68102405630422458",
            "479afd41188b46938215f7afc3d5956c"
          ]
        },
        "id": "wIV6EOpJSFZs",
        "outputId": "7ee5d642-0986-4dc3-9a6b-de1756f8ce40"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4885cf8a79fe4f159aeaa4e00d11b02f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4979cd76548a43599714d61174477995",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9040628fe39841b0aaffe8fe19b616e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess(examples):\n",
        "  inputs = tokenizer(\n",
        "      examples[\"text\"],\n",
        "      padding=\"max_length\",\n",
        "      truncation=True,\n",
        "      max_length = 128\n",
        "  )\n",
        "  inputs['labels'] = examples['label']\n",
        "  return inputs\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess, batched=True)\n",
        "\n",
        "# encoded_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4MGCQClXX8E",
        "outputId": "64e0ee4b-a311-4c65-8d46-d01fa742628f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column([[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2572, 3110, 24665, 7140, 11714, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "print(encoded_dataset['train']['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVs4HjRIph6U",
        "outputId": "ea813349-6e9e-4ec1-92d1-4e447686dfe7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 16000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYQts6ONl_Cg"
      },
      "source": [
        "## Loading & Evaluating a Foundation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TJcxGuJs_W7",
        "outputId": "9f859c9d-fafe-4753-b700-61ca94503945"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
        "\n",
        "# Apply LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"query\", \"value\"]\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnCa-sFimdTn"
      },
      "source": [
        "## Performing Parameter-Efficient Fine-Tuning (PEFT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "TDytVW30uGjS",
        "outputId": "6587f1a4-17db-48d8-f063-203d276c584f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-10-2245952336.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 12:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.046500</td>\n",
              "      <td>0.905324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.769700</td>\n",
              "      <td>0.743916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.688285</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3000, training_loss=0.9442581179936727, metrics={'train_runtime': 742.2658, 'train_samples_per_second': 64.667, 'train_steps_per_second': 4.042, 'total_flos': 3168487784448000.0, 'train_loss': 0.9442581179936727, 'epoch': 3.0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    eval_strategy=\"epoch\", # Changed from evaluation_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=10,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHDqI3NadHhA"
      },
      "source": [
        "option 1: save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjsBIGhTckTC",
        "outputId": "6d853e42-b890-4508-c300-bb1c2b268a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/trained_model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/trained_model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/trained_model/vocab.txt',\n",
              " '/content/drive/MyDrive/trained_model/added_tokens.json',\n",
              " '/content/drive/MyDrive/trained_model/tokenizer.json')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/trained_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/trained_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og6jB-k7dMEk"
      },
      "source": [
        "option 2: load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2vgcfMndNrP",
        "outputId": "5cf6ae0f-aaea-49b3-a8a5-0bb00e3d5794"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "# Load base model (same model you used when training with PEFT)\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)\n",
        "\n",
        "# Load PEFT adapter on top of base model\n",
        "model = PeftModel.from_pretrained(base_model, \"/content/drive/MyDrive/trained_model\")\n",
        "\n",
        "# Load tokenizer (either from original or saved tokenizer)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/trained_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY8SjtAMdWdC"
      },
      "source": [
        "## Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DKE0WhedXwx",
        "outputId": "dcf267f2-a9e2-4844-9cf3-9faec94fac66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello nice to meet you!\n",
            "üéØ Predicted Emotion: joy (score: 0.80)\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "emotion_classifier = pipeline(\"text-classification\", model=trainer.model, tokenizer=tokenizer)\n",
        "\n",
        "text = input()\n",
        "\n",
        "prediction = emotion_classifier(text)[0]\n",
        "\n",
        "pred_label_id = int(prediction[\"label\"].split(\"_\")[-1])\n",
        "pred_emotion = label_to_string(pred_label_id)\n",
        "\n",
        "print(f\"üéØ Predicted Emotion: {pred_emotion} (score: {prediction['score']:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3J76B08uDO8"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0gbm6gi8Zos0"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XGm8VNOfZwPa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(model, dataset, tokenizer):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "    device = model.device\n",
        "\n",
        "    for example in tqdm(dataset):\n",
        "        inputs = tokenizer(\n",
        "            example[\"text\"],\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            pred = torch.argmax(logits, dim=1).item()\n",
        "        preds.append(pred)\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    acc = accuracy_metric.compute(predictions=preds, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
        "\n",
        "    return acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz4N7m0ZZ31E",
        "outputId": "5c735b9e-bd38-4eda-ec94-ab692a507cf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [04:45<00:00,  7.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìò Trained LoRA Model:\n",
            " - Accuracy: 0.7670 | F1: 0.7291\n"
          ]
        }
      ],
      "source": [
        "acc_lora, f1_lora = evaluate_model(model, dataset[\"test\"], tokenizer)\n",
        "print(f\"üìò Trained LoRA Model:\\n - Accuracy: {acc_lora['accuracy']:.4f} | F1: {f1_lora['f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJYGsxNWaM-K",
        "outputId": "34a2493d-cdf4-4a63-92a3-06e15060b28f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [04:14<00:00,  7.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìï Base Model (Untrained):\n",
            " - Accuracy: 0.2680 | F1: 0.2032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
        "\n",
        "acc_base, f1_base = evaluate_model(base_model, dataset[\"test\"], tokenizer)\n",
        "print(f\"üìï Base Model (Untrained):\\n - Accuracy: {acc_base['accuracy']:.4f} | F1: {f1_base['f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "SGCiv9bObqYE",
        "outputId": "070f78e4-9f04-442f-dd75-486a85e0dc5b"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### üìä **Prediction Comparison on Sample Test Cases**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"\\ud83d\\udcdd Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"im updating my blog because i feel shitty\",\n          \"i was feeling a little vain when i did this one\",\n          \"i never make her separate from me because i don t ever want her to feel like i m ashamed with her\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u2705 True Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"joy\",\n          \"sadness\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud83d\\udcd5 Base Model Prediction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fear\",\n          \"joy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud83d\\udcd8 LoRA Model Prediction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"joy\",\n          \"sadness\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5366fdb5-6bdf-4607-b310-40e3825d7189\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>üìù Text</th>\n",
              "      <th>‚úÖ True Label</th>\n",
              "      <th>üìï Base Model Prediction</th>\n",
              "      <th>üìò LoRA Model Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im updating my blog because i feel shitty</td>\n",
              "      <td>sadness</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i never make her separate from me because i do...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>fear</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i was feeling a little vain when i did this one</td>\n",
              "      <td>sadness</td>\n",
              "      <td>fear</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5366fdb5-6bdf-4607-b310-40e3825d7189')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5366fdb5-6bdf-4607-b310-40e3825d7189 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5366fdb5-6bdf-4607-b310-40e3825d7189');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1235e5fd-6f59-4acc-889a-cc398171bd12\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1235e5fd-6f59-4acc-889a-cc398171bd12')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1235e5fd-6f59-4acc-889a-cc398171bd12 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3f294297-4f49-4dff-aacd-ba22407ed68b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3f294297-4f49-4dff-aacd-ba22407ed68b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              üìù Text ‚úÖ True Label  \\\n",
              "0  im feeling rather rotten so im not very ambiti...      sadness   \n",
              "1          im updating my blog because i feel shitty      sadness   \n",
              "2  i never make her separate from me because i do...      sadness   \n",
              "3  i left with my bouquet of red and yellow tulip...          joy   \n",
              "4    i was feeling a little vain when i did this one      sadness   \n",
              "\n",
              "  üìï Base Model Prediction üìò LoRA Model Prediction  \n",
              "0                     joy                 sadness  \n",
              "1                     joy                 sadness  \n",
              "2                    fear                 sadness  \n",
              "3                     joy                     joy  \n",
              "4                    fear                 sadness  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "\n",
              "### üßÆ **Overall Evaluation**\n",
              "| Model | Accuracy | F1 Score |\n",
              "|-------|----------|----------|\n",
              "| üìï Base BERT | **0.2680** | **0.2032** |\n",
              "| üìò LoRA Fine-tuned | **0.7670** | **0.7291** |\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "sample_dataset = dataset[\"test\"].select(range(5))\n",
        "sample_texts = sample_dataset[\"text\"]\n",
        "true_labels = sample_dataset[\"label\"]\n",
        "\n",
        "def predict_labels(model, texts):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for text in texts:\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(model.device)\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            pred = torch.argmax(logits, dim=1).item()\n",
        "            preds.append(pred)\n",
        "    return preds\n",
        "\n",
        "base_preds = predict_labels(base_model, sample_texts)\n",
        "lora_preds = predict_labels(model, sample_texts)\n",
        "\n",
        "def id_to_label(idx):\n",
        "    return label_map[idx]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"üìù Text\": sample_texts,\n",
        "    \"‚úÖ True Label\": [id_to_label(l) for l in true_labels],\n",
        "    \"üìï Base Model Prediction\": [id_to_label(p) for p in base_preds],\n",
        "    \"üìò LoRA Model Prediction\": [id_to_label(p) for p in lora_preds],\n",
        "})\n",
        "\n",
        "display(Markdown(\"### üìä **Prediction Comparison on Sample Test Cases**\"))\n",
        "display(df)\n",
        "\n",
        "display(Markdown(f\"\"\"\n",
        "### üßÆ **Overall Evaluation**\n",
        "| Model | Accuracy | F1 Score |\n",
        "|-------|----------|----------|\n",
        "| üìï Base BERT | **{acc_base['accuracy']:.4f}** | **{f1_base['f1']:.4f}** |\n",
        "| üìò LoRA Fine-tuned | **{acc_lora['accuracy']:.4f}** | **{f1_lora['f1']:.4f}** |\n",
        "\"\"\"))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyP8IRUhCAhMOpK6fcStnJPd",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
